1、kafka部署时如何规划磁盘容量？
    考虑点
    * 新增消息数
    * 消息大小
    * 消息留存时间
    * 是否开启压缩
    * 备份数

2、Kafka数据丢失
    1) 生产者程序数据丢失
        生产者调用消息发送接口， producer.send(msg), 接口会立即返回但是此时消息未必成功发送到broker，比如因为网络抖动、消息不合格导致broker拒收
        * 可以通过producer.send(msg, callback)来解决，消息发送失败，应由生产者解决而非broker
        * 设置ack=all 所有副本都收到消息才认为消息提交成功
        * retries 设置为一个大于1的值，当网络异常这种就可以通过重试保证消息发送成功
    2) 消费者数据丢失
        消费者端的一个概念是offset，消费者消费到指定的offset位置，如果是先更新消费位置，再消费消息，就有可能在二者之间发生异常导致消息没有被消息而丢失
        * 可以通过先消费消息，再更新偏移量来解决消息丢失的问题，会引入重复消费的问题，后面说
        == consumer的位移和分区内的位移不是一个概念，但是名字都是offset， 消费者端记录的位移是下一条要消费的消息的offset
    3) Broker
        设置参数 min_insync_replicas > 1 ，控制消息至少被写入n个副本才认为是已提交

3、位移提交
    1)因为consumer可以消费多个分区，所以位移提交是分区粒度的，kafka的位移提交十分灵活，即可随意提交位移offset，但是后果是造成消息丢失、重复消费等
    2)kafka的 kafkaConsumer Api 提供了多种位移提交方式
        * 用户角度包括：自动提交、手动提交  enable.auto.commit = true // 自动提交
        * consumer角度：同步提交、异步提交
    a: 自动提交 默认情况下，kafka每5s自动提交一次位移， 自动提交会引入重复消费问题(提交后的第二秒发生rebalance，那这两秒的数据都需要重新消费一次)，
       可以通过调整自动提交的间隔来减少重复消费的消息数，但是不能消除
    b: 手动提交 好处是可以控制提交时机和频率；缺点是在提交时，调用commitSync()时consumer会处于阻塞状态，直到broker返回结果才可以；手动提交还有一个commitAsync()是异步的
       优点是不阻塞，缺点是异常无法重试

    c: 同步异步混合使用，使用异步提交，异常后使用同步模式重试